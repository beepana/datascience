{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09\n",
    "---\n",
    "\n",
    "## DataStore\n",
    "- RDMS (SQLite, MYSQL, PostgreSQL)\n",
    "- Text Format (CSV, JSON )[\n",
    "- NoSQL (MongoDB, CouchDB)\n",
    "- Fast Binary (HDF5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mongodb uses bson\n",
    "- reader is an iterator object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv.DictReader at 0x114e80c88>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.DictReader(open('names.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('id', '1'), (' firstname', ' harry'), (' lastname', ' potter'), (' age', ' 17')]), OrderedDict([('id', '2'), (' firstname', ' hermaline'), (' lastname', ' granger'), (' age', ' 17')]), OrderedDict([('id', '3'), (' firstname', ' Ron'), (' lastname', ' weasles'), (' age', ' 18')]), OrderedDict([('id', '4'), (' firstname', ' nayna'), (' lastname', ' pathak'), (' age', ' 195'), (None, ['beepana', 'pokharel', '23'])]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')]), OrderedDict([('id', '5'), (' firstname', 'beepana'), (' lastname', 'pokharel'), (' age', '23')])]\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    print(list(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import  OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Color = namedtuple('Color', ['red' ,'green', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Color(123,189,165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " harry\n",
      " hermaline\n",
      " Ron\n",
      " nayna\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for line in reader:\n",
    "        print(line[' firstname'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " firstname\n",
      " harry\n",
      " hermaline\n",
      " Ron\n",
      " nayna\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames = ['id','firstname','lastname','age'])\n",
    "    for line in reader:\n",
    "        print(line['firstname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv.DictReader?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " harry\n",
      " hermaline\n",
      " Ron\n",
      " nayna\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n",
      "beepana\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames = ['id','firstname','lastname','age'])\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        print(line['firstname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = iter([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'a') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = ['id','firstname','lastname','age'])\n",
    "    writer.writerow({'id':5,'firstname':'beepana','lastname':'pokharel','age':23})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'a') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = ['id','firstname','lastname','age'])\n",
    "    writer.writerows([{'id':5,'firstname':'beepana','lastname':'pokharel','age':23}\n",
    "                    ,{'id':5,'firstname':'beepana','lastname':'pokharel','age':23}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data.sqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table characters already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-ddcb7d5fcdf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CREATE TABLE characters(id integer, firstname text, lastname text,age integer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: table characters already exists"
     ]
    }
   ],
   "source": [
    "cur.execute('CREATE TABLE characters(id integer, firstname text, lastname text,age integer)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x114e08420>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('INSERT INTO characters VALUES(1,\"harry\",\"potter\",17) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql =\"\"\"INSERT INTO characters VALUES(?,?,?,?)\"\"\"\n",
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames = ['id','firstname','lastname','age'])\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        cur.execute(sql,(line['id'],line['firstname'],line['lastname'],line['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<built-in function id>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-dd358410f171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"INSERT INTO charcters(id) VALUES(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: <built-in function id>"
     ]
    }
   ],
   "source": [
    "\"INSERT INTO charcters(id) VALUES(\" + line[id] +\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sql injection prevented from the above 1st code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x114e08420>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"UPDATE characters SET age=age+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x114e08420>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('UPDATE characters SET age=age+2 WHERE firstname=\"harry\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf = h5py.File('datasets.h5','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 =  hf.create_group('ktm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"datasets.h5\" (mode r+)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm\" (0 members)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm/substation1\" (0 members)>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.create_group('substation1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm\" (1 members)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg2 = g1.create_group('substation2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm\" (2 members)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"datasets.h5\" (mode r+)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = sg2.create_dataset('satellite_image',(100,),dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"satellite_image\": shape (100,), type \"<i4\">"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dataset in module h5py._hl.dataset object:\n",
      "\n",
      "class Dataset(h5py._hl.base.HLObject)\n",
      " |  Represents an HDF5 dataset\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      h5py._hl.base.HLObject\n",
      " |      h5py._hl.base.CommonStateObject\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |      Create a Numpy array containing the whole dataset.  DON'T THINK\n",
      " |      THIS MEANS DATASETS ARE INTERCHANGABLE WITH ARRAYS.  For one thing,\n",
      " |      you have to read the whole dataset everytime this method is called.\n",
      " |  \n",
      " |  __getitem__(self, args)\n",
      " |      Read a slice from the HDF5 dataset.\n",
      " |      \n",
      " |      Takes slices and recarray-style field names (more than one is\n",
      " |      allowed!) in any order.  Obeys basic NumPy rules, including\n",
      " |      broadcasting.\n",
      " |      \n",
      " |      Also supports:\n",
      " |      \n",
      " |      * Boolean \"mask\" array indexing\n",
      " |  \n",
      " |  __init__(self, bind)\n",
      " |      Create a new Dataset object by binding to a low-level DatasetID.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      BEWARE: Modifications to the yielded data are *NOT* written to file.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Limited to 2**32 on 32-bit systems; Dataset.len() is preferred.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setitem__(self, args, val)\n",
      " |      Write to the HDF5 dataset from a Numpy array.\n",
      " |      \n",
      " |      NumPy's broadcasting rules are honored, for \"simple\" indexing\n",
      " |      (slices and integers).  For advanced indexing, the shapes must\n",
      " |      match.\n",
      " |  \n",
      " |  astype(self, dtype)\n",
      " |      Get a context manager allowing you to perform reads to a\n",
      " |      different destination type, e.g.:\n",
      " |      \n",
      " |      >>> with dataset.astype('f8'):\n",
      " |      ...     double_precision = dataset[0:100:2]\n",
      " |  \n",
      " |  len(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Use of this method is preferred to len(dset), as Python's built-in\n",
      " |      len() cannot handle values greater then 2**32 on 32-bit systems.\n",
      " |  \n",
      " |  read_direct(self, dest, source_sel=None, dest_sel=None)\n",
      " |      Read data directly from HDF5 into an existing NumPy array.\n",
      " |      \n",
      " |      The destination array must be C-contiguous and writable.\n",
      " |      Selections must be the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  resize(self, size, axis=None)\n",
      " |      Resize the dataset, or the specified axis.\n",
      " |      \n",
      " |      The dataset must be stored in chunked format; it can be resized up to\n",
      " |      the \"maximum shape\" (keyword maxshape) specified at creation time.\n",
      " |      The rank of the dataset cannot be changed.\n",
      " |      \n",
      " |      \"Size\" should be a shape tuple, or if an axis is specified, an integer.\n",
      " |      \n",
      " |      BEWARE: This functions differently than the NumPy resize() method!\n",
      " |      The data is not \"reshuffled\" to fit in the new shape; each axis is\n",
      " |      grown or shrunk independently.  The coordinates of existing data are\n",
      " |      fixed.\n",
      " |  \n",
      " |  write_direct(self, source, source_sel=None, dest_sel=None)\n",
      " |      Write data directly to HDF5 from a NumPy array.\n",
      " |      \n",
      " |      The source array must be C-contiguous.  Selections must be\n",
      " |      the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  chunks\n",
      " |      Dataset chunks (or None)\n",
      " |  \n",
      " |  compression\n",
      " |      Compression strategy (or None)\n",
      " |  \n",
      " |  compression_opts\n",
      " |      Compression setting.  Int(0-9) for gzip, 2-tuple for szip.\n",
      " |  \n",
      " |  dims\n",
      " |      Access dimension scales attached to this dataset.\n",
      " |  \n",
      " |  dtype\n",
      " |      Numpy dtype representing the datatype\n",
      " |  \n",
      " |  fillvalue\n",
      " |      Fill value for this dataset (0 by default)\n",
      " |  \n",
      " |  fletcher32\n",
      " |      Fletcher32 filter is present (T/F)\n",
      " |  \n",
      " |  maxshape\n",
      " |      Shape up to which this dataset can be resized.  Axes with value\n",
      " |      None have no resize limit.\n",
      " |  \n",
      " |  ndim\n",
      " |      Numpy-style attribute giving the number of dimensions\n",
      " |  \n",
      " |  scaleoffset\n",
      " |      Scale/offset filter settings. For integer data types, this is\n",
      " |      the number of bits stored, or 0 for auto-detected. For floating\n",
      " |      point data types, this is the number of decimal places retained.\n",
      " |      If the scale/offset filter is not in use, this is None.\n",
      " |  \n",
      " |  shape\n",
      " |      Numpy-style shape tuple giving dataset dimensions\n",
      " |  \n",
      " |  shuffle\n",
      " |      Shuffle filter present (T/F)\n",
      " |  \n",
      " |  size\n",
      " |      Numpy-style attribute giving the total dataset size\n",
      " |  \n",
      " |  value\n",
      " |      Alias for dataset[()]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  attrs\n",
      " |      Attributes attached to this object\n",
      " |  \n",
      " |  file\n",
      " |      Return a File instance associated with this object\n",
      " |  \n",
      " |  id\n",
      " |      Low-level identifier appropriate for this object\n",
      " |  \n",
      " |  name\n",
      " |      Return the full name of this object.  None if anonymous.\n",
      " |  \n",
      " |  parent\n",
      " |      Return the parent group of this object.\n",
      " |      \n",
      " |      This is always equivalent to obj.file[posixpath.dirname(obj.name)].\n",
      " |      ValueError if this object is anonymous.\n",
      " |  \n",
      " |  ref\n",
      " |      An (opaque) HDF5 reference to this object\n",
      " |  \n",
      " |  regionref\n",
      " |      Create a region reference (Datasets only).\n",
      " |      \n",
      " |      The syntax is regionref[<slices>]. For example, dset.regionref[...]\n",
      " |      creates a region reference in which the whole dataset is selected.\n",
      " |      \n",
      " |      Can also be used to determine the shape of the referenced dataset\n",
      " |      (via .shape property), or the shape of the selection (via the\n",
      " |      .selection property).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.CommonStateObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt2 = sg2.create_dataset('random',data = np.arange(0,12).reshape(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
